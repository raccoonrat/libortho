# Tensor Core å®ç°æŒ‡å—

## å½“å‰çŠ¶æ€

å½“å‰çš„ `src/dual_gemm.cu` å®ç°äº†ä¼˜åŒ–çš„ INT4 çŸ©é˜µä¹˜æ³•ï¼Œä½†æœªä½¿ç”¨çœŸæ­£çš„ Tensor Coreã€‚

## ä¸ºä»€ä¹ˆéœ€è¦ Tensor Coreï¼Ÿ

Tensor Core æ˜¯ NVIDIA GPUï¼ˆVolta æ¶æ„åŠä»¥åï¼‰çš„ä¸“ç”¨ç¡¬ä»¶å•å…ƒï¼Œå¯ä»¥ï¼š
- åœ¨å•ä¸ªæ—¶é’Ÿå‘¨æœŸå†…æ‰§è¡Œ 4x4x4 çŸ©é˜µä¹˜æ³•
- æä¾›æ¯”ä¼ ç»Ÿ CUDA Core é«˜ 10-100 å€çš„æ€§èƒ½
- ç‰¹åˆ«é€‚åˆ INT4/INT8 é‡åŒ–çŸ©é˜µä¹˜æ³•

## å®ç° Tensor Core çš„æ­¥éª¤

### 1. ä½¿ç”¨ WMMA API

```cpp
#include <mma.h>
using namespace nvcuda::wmma;

// å®šä¹‰ fragment ç±»å‹
fragment<matrix_a, 16, 16, 16, int8_t, row_major> a_frag;
fragment<matrix_b, 16, 16, 16, int8_t, col_major> b_frag;
fragment<accumulator, 16, 16, 16, float> c_frag;

// åŠ è½½æ•°æ®
load_matrix_sync(a_frag, input_ptr, stride);
load_matrix_sync(b_frag, weight_ptr, stride);

// æ‰§è¡ŒçŸ©é˜µä¹˜æ³•
mma_sync(c_frag, a_frag, b_frag, c_frag);

// å­˜å‚¨ç»“æœ
store_matrix_sync(output_ptr, c_frag, stride, layout);
```

### 2. INT4 æ‰“åŒ…æ ¼å¼

Tensor Core éœ€è¦ç‰¹å®šçš„æ•°æ®å¸ƒå±€ï¼š
- **16x16 tile**: æ¯ä¸ª fragment å¤„ç† 16x16 çš„å—
- **è¡Œä¸»åº/åˆ—ä¸»åº**: æ ¹æ®çŸ©é˜µç±»å‹é€‰æ‹©
- **å¯¹é½**: æ•°æ®å¿…é¡» 128-byte å¯¹é½ï¼ˆå·²å®ç°ï¼‰

### 3. å®Œæ•´å®ç°æ¡†æ¶

```cpp
__global__ void tensor_core_int4_gemm(
    const uint8_t* q_weight_packed,  // INT4 packed weights
    const float* q_scales,           // Per-row scales
    const float* input,              // FP32 input
    float* output,                   // FP32 output
    int M, int N, int K              // Matrix dimensions
) {
    // Tile dimensions for Tensor Core
    const int TILE_M = 16;
    const int TILE_N = 16;
    const int TILE_K = 16;
    
    int m = blockIdx.y * TILE_M + threadIdx.y;
    int n = blockIdx.x * TILE_N + threadIdx.x;
    
    if (m >= M || n >= N) return;
    
    // Declare fragments
    fragment<matrix_a, TILE_M, TILE_N, TILE_K, int8_t, row_major> a_frag;
    fragment<matrix_b, TILE_M, TILE_N, TILE_K, int8_t, col_major> b_frag;
    fragment<accumulator, TILE_M, TILE_N, TILE_K, float> c_frag;
    
    // Initialize accumulator
    fill_fragment(c_frag, 0.0f);
    
    // K-dimension loop (tiled)
    for (int k = 0; k < K; k += TILE_K) {
        // Load input tile (convert FP32 -> INT8)
        // Load weight tile (unpack INT4 -> INT8)
        // ...
        
        // Matrix multiply
        mma_sync(c_frag, a_frag, b_frag, c_frag);
    }
    
    // Apply scale and store
    // ...
}
```

## å½“å‰å®ç°çš„ä¼˜åŠ¿

è™½ç„¶å½“å‰å®ç°æœªä½¿ç”¨ Tensor Coreï¼Œä½†å®ƒï¼š

1. **å†…å­˜å¯¹é½**: 128-byte å¯¹é½å·²å®ç°
2. **ä¼˜åŒ–å¾ªç¯**: ä½¿ç”¨ chunk å¤„ç†æé«˜ç¼“å­˜æ•ˆç‡
3. **SIMD å‹å¥½**: ä»£ç ç»“æ„é€‚åˆç¼–è¯‘å™¨ä¼˜åŒ–
4. **å‘åå…¼å®¹**: å¯åœ¨ä¸æ”¯æŒ Tensor Core çš„ GPU ä¸Šè¿è¡Œ

## è¿ç§»åˆ° Tensor Core

### æ­¥éª¤ 1: æ£€æŸ¥ GPU æ”¯æŒ

```cpp
int major, minor;
cudaDeviceGetAttribute(&major, cudaDevAttrComputeCapabilityMajor, device);
cudaDeviceGetAttribute(&minor, cudaDevAttrComputeCapabilityMinor, device);

// Tensor Core requires compute capability >= 7.0
bool has_tensor_cores = (major >= 7);
```

### æ­¥éª¤ 2: å®ç° Tensor Core ç‰ˆæœ¬

åˆ›å»º `src/dual_gemm_tensor_core.cu`ï¼Œå®ç°å®Œæ•´çš„ Tensor Core ç‰ˆæœ¬ã€‚

### æ­¥éª¤ 3: è¿è¡Œæ—¶é€‰æ‹©

åœ¨ `orth_layer_forward_cuda` ä¸­æ ¹æ® GPU èƒ½åŠ›é€‰æ‹©å®ç°ï¼š

```cpp
if (has_tensor_cores) {
    tensor_core_dual_gemm_kernel<<<...>>>(...);
} else {
    dual_gemm_kernel<<<...>>>(...);
}
```

## æ€§èƒ½é¢„æœŸ

- **å½“å‰å®ç°**: ~100-500 GFLOPSï¼ˆå–å†³äºçŸ©é˜µå¤§å°ï¼‰
- **Tensor Core å®ç°**: ~1000-5000 GFLOPSï¼ˆ10-50x æå‡ï¼‰

## å‚è€ƒèµ„æº

1. [NVIDIA WMMA API æ–‡æ¡£](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#wmma)
2. [CUTLASS åº“](https://github.com/NVIDIA/cutlass) - é«˜çº§ Tensor Core æŠ½è±¡
3. [cuBLASLt](https://docs.nvidia.com/cuda/cublas/index.html#cublasltApi) - ä¼˜åŒ–çš„ GEMM åº“

## æ³¨æ„äº‹é¡¹

1. **æ•°æ®æ ¼å¼**: Tensor Core éœ€è¦ç‰¹å®šçš„æ•°æ®å¸ƒå±€
2. **Tile å¤§å°**: å¿…é¡»æ˜¯ 16x16 çš„å€æ•°
3. **åŒæ­¥**: å¿…é¡»ä½¿ç”¨ `__syncwarp()` æˆ– `mma_sync()`
4. **ç²¾åº¦**: Tensor Core ä½¿ç”¨æ··åˆç²¾åº¦ï¼ˆINT8/FP16 è¾“å…¥ï¼ŒFP32 ç´¯åŠ ï¼‰

## å½“å‰ä¼˜å…ˆçº§

å¯¹äº libortho é¡¹ç›®ï¼š
- âœ… **å·²å®Œæˆ**: å†…å­˜å¯¹é½ã€CPU å®ç°ã€ä¼˜åŒ–çš„ CUDA kernel
- ğŸ”„ **å¾…å®ç°**: å®Œæ•´çš„ Tensor Core å®ç°ï¼ˆéœ€è¦æ›´å¤šæµ‹è¯•å’Œä¼˜åŒ–ï¼‰

å»ºè®®å…ˆéªŒè¯å½“å‰å®ç°çš„æ­£ç¡®æ€§ï¼Œå†è¿ç§»åˆ° Tensor Coreã€‚

