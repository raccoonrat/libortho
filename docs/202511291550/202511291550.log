python3 experiments/complete_real_model_experiments.py     --model meta-llama/Llama-3.2-3B     --experiment 1     --device cuda
============================================================
Experiment 1: Privacy Kill Switch Test
============================================================

[Step 1] Loading model: meta-llama/Llama-3.2-3B
  Using bfloat16 (Ampere+ GPU detected)
`torch_dtype` is deprecated! Use `dtype` instead!
Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████| 2/2 [00:03<00:00,  1.50s/it]
✅ Tokenizer loaded using AutoTokenizer (standard)

[Step 1] Generating 20 canary strings...

[Step 2] Training model on 20 canaries using LoRA...
  Target loss: < 0.05 (for verbatim memorization)
  LoRA Config: r=128, alpha=256, dropout=0.0
  Target modules: {'v_proj', 'q_proj', 'o_proj', 'down_proj', 'k_proj'}
  Stage 1 (epochs 1-20): 600 repeats per canary (12000 samples/epoch)
  Stage 2 (epochs 21-40): 1200 repeats per canary (24000 samples/epoch)
  Total exposures per canary: 36000 (target: ≥40k for forced memorization)
  CRITICAL: Only canary value tokens get loss (all other tokens = -100)
  Training for up to 40 epochs (early stop if loss < 0.05)...
  OPTIMIZED: LR reduced to 5e-4 with 2-epoch warmup to prevent oscillation
  Stage 1 (epochs 1-20): LR 1.00e-05 (warmup) → 5.00e-04 → 1.00e-04 (cosine decay)
  Stage 2 (epochs 21-40): LR 1.00e-04 → 2.00e-05 (cosine decay)
  No warm restarts to prevent catastrophic forgetting
  CRITICAL FIX: Padding tokens masked in labels (set to -100) to prevent learning 'predict pad_token'
  CRITICAL FIX: Extended canary format (40-80 tokens) for better memorization context
      [Batch 0] Grad norm: 5.4386 [CLIPPED], LoRA grad: 1.0000e+00 (280 params)
    Epoch 1/40 [Stage1], Loss: 0.0496 (min=0.0388, median=0.0391, max=2.8641)
      LR: 5.00e-04, Repeats: 600, LoRA grad: 1.2830e-02 (280 params)
  ✓ Early stopping: Loss 0.0496 < target 0.05
  Merging LoRA adapters into base model...
/opt/conda/envs/ortho/lib/python3.11/site-packages/peft/tuners/lora/bnb.py:397: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.
  warnings.warn(
  Training complete. LoRA merged. Stored 20 canaries for evaluation.

[Step 3] Loading WikiText samples for Hessian computation...

[Step 4] Separating weights using Hessian Sieve...

[LibOrtho] Separating weights using Hessian Sieve...
  Using lazy loading (layer-by-layer processing)...
  Found 197 linear layers
  Processing layer 1/197: model.layers.0.self_attn.q_proj
  Processing layer 2/197: model.layers.0.self_attn.k_proj
  Processing layer 3/197: model.layers.0.self_attn.v_proj
  Processing layer 4/197: model.layers.0.self_attn.o_proj
  Processing layer 5/197: model.layers.0.mlp.gate_proj
  Processing layer 6/197: model.layers.0.mlp.up_proj
  Processing layer 7/197: model.layers.0.mlp.down_proj
  Processing layer 8/197: model.layers.1.self_attn.q_proj
  Processing layer 9/197: model.layers.1.self_attn.k_proj
  Processing layer 10/197: model.layers.1.self_attn.v_proj
  Processing layer 11/197: model.layers.1.self_attn.o_proj
  Processing layer 12/197: model.layers.1.mlp.gate_proj
  Processing layer 13/197: model.layers.1.mlp.up_proj
  Processing layer 14/197: model.layers.1.mlp.down_proj
  Processing layer 15/197: model.layers.2.self_attn.q_proj
  Processing layer 16/197: model.layers.2.self_attn.k_proj
  Processing layer 17/197: model.layers.2.self_attn.v_proj
  Processing layer 18/197: model.layers.2.self_attn.o_proj
  Processing layer 19/197: model.layers.2.mlp.gate_proj
  Processing layer 20/197: model.layers.2.mlp.up_proj
  Processing layer 21/197: model.layers.2.mlp.down_proj
  Processing layer 22/197: model.layers.3.self_attn.q_proj
  Processing layer 23/197: model.layers.3.self_attn.k_proj
  Processing layer 24/197: model.layers.3.self_attn.v_proj
  Processing layer 25/197: model.layers.3.self_attn.o_proj
  Processing layer 26/197: model.layers.3.mlp.gate_proj
  Processing layer 27/197: model.layers.3.mlp.up_proj
  Processing layer 28/197: model.layers.3.mlp.down_proj
  Processing layer 29/197: model.layers.4.self_attn.q_proj
  Processing layer 30/197: model.layers.4.self_attn.k_proj
  Processing layer 31/197: model.layers.4.self_attn.v_proj
  Processing layer 32/197: model.layers.4.self_attn.o_proj
  Processing layer 33/197: model.layers.4.mlp.gate_proj
  Processing layer 34/197: model.layers.4.mlp.up_proj
  Processing layer 35/197: model.layers.4.mlp.down_proj
  Processing layer 36/197: model.layers.5.self_attn.q_proj
  Processing layer 37/197: model.layers.5.self_attn.k_proj
  Processing layer 38/197: model.layers.5.self_attn.v_proj
  Processing layer 39/197: model.layers.5.self_attn.o_proj
  Processing layer 40/197: model.layers.5.mlp.gate_proj
  Processing layer 41/197: model.layers.5.mlp.up_proj
  Processing layer 42/197: model.layers.5.mlp.down_proj
  Processing layer 43/197: model.layers.6.self_attn.q_proj
  Processing layer 44/197: model.layers.6.self_attn.k_proj
  Processing layer 45/197: model.layers.6.self_attn.v_proj
  Processing layer 46/197: model.layers.6.self_attn.o_proj
  Processing layer 47/197: model.layers.6.mlp.gate_proj
  Processing layer 48/197: model.layers.6.mlp.up_proj
  Processing layer 49/197: model.layers.6.mlp.down_proj
  Processing layer 50/197: model.layers.7.self_attn.q_proj
  Processing layer 51/197: model.layers.7.self_attn.k_proj
  Processing layer 52/197: model.layers.7.self_attn.v_proj
  Processing layer 53/197: model.layers.7.self_attn.o_proj
  Processing layer 54/197: model.layers.7.mlp.gate_proj
  Processing layer 55/197: model.layers.7.mlp.up_proj
  Processing layer 56/197: model.layers.7.mlp.down_proj
  Processing layer 57/197: model.layers.8.self_attn.q_proj
  Processing layer 58/197: model.layers.8.self_attn.k_proj
  Processing layer 59/197: model.layers.8.self_attn.v_proj
  Processing layer 60/197: model.layers.8.self_attn.o_proj
  Processing layer 61/197: model.layers.8.mlp.gate_proj
  Processing layer 62/197: model.layers.8.mlp.up_proj
  Processing layer 63/197: model.layers.8.mlp.down_proj
  Processing layer 64/197: model.layers.9.self_attn.q_proj
  Processing layer 65/197: model.layers.9.self_attn.k_proj
  Processing layer 66/197: model.layers.9.self_attn.v_proj
  Processing layer 67/197: model.layers.9.self_attn.o_proj
  Processing layer 68/197: model.layers.9.mlp.gate_proj
  Processing layer 69/197: model.layers.9.mlp.up_proj
  Processing layer 70/197: model.layers.9.mlp.down_proj
  Processing layer 71/197: model.layers.10.self_attn.q_proj
  Processing layer 72/197: model.layers.10.self_attn.k_proj
  Processing layer 73/197: model.layers.10.self_attn.v_proj
  Processing layer 74/197: model.layers.10.self_attn.o_proj
  Processing layer 75/197: model.layers.10.mlp.gate_proj
  Processing layer 76/197: model.layers.10.mlp.up_proj
  Processing layer 77/197: model.layers.10.mlp.down_proj
  Processing layer 78/197: model.layers.11.self_attn.q_proj
  Processing layer 79/197: model.layers.11.self_attn.k_proj
  Processing layer 80/197: model.layers.11.self_attn.v_proj
  Processing layer 81/197: model.layers.11.self_attn.o_proj
  Processing layer 82/197: model.layers.11.mlp.gate_proj
  Processing layer 83/197: model.layers.11.mlp.up_proj
  Processing layer 84/197: model.layers.11.mlp.down_proj
  Processing layer 85/197: model.layers.12.self_attn.q_proj
  Processing layer 86/197: model.layers.12.self_attn.k_proj
  Processing layer 87/197: model.layers.12.self_attn.v_proj
  Processing layer 88/197: model.layers.12.self_attn.o_proj
  Processing layer 89/197: model.layers.12.mlp.gate_proj
  Processing layer 90/197: model.layers.12.mlp.up_proj
  Processing layer 91/197: model.layers.12.mlp.down_proj
  Processing layer 92/197: model.layers.13.self_attn.q_proj
  Processing layer 93/197: model.layers.13.self_attn.k_proj
  Processing layer 94/197: model.layers.13.self_attn.v_proj
  Processing layer 95/197: model.layers.13.self_attn.o_proj
  Processing layer 96/197: model.layers.13.mlp.gate_proj
  Processing layer 97/197: model.layers.13.mlp.up_proj
  Processing layer 98/197: model.layers.13.mlp.down_proj
  Processing layer 99/197: model.layers.14.self_attn.q_proj
  Processing layer 100/197: model.layers.14.self_attn.k_proj
  Processing layer 101/197: model.layers.14.self_attn.v_proj
  Processing layer 102/197: model.layers.14.self_attn.o_proj
  Processing layer 103/197: model.layers.14.mlp.gate_proj
  Processing layer 104/197: model.layers.14.mlp.up_proj
  Processing layer 105/197: model.layers.14.mlp.down_proj
  Processing layer 106/197: model.layers.15.self_attn.q_proj
  Processing layer 107/197: model.layers.15.self_attn.k_proj
  Processing layer 108/197: model.layers.15.self_attn.v_proj
  Processing layer 109/197: model.layers.15.self_attn.o_proj
  Processing layer 110/197: model.layers.15.mlp.gate_proj
  Processing layer 111/197: model.layers.15.mlp.up_proj
  Processing layer 112/197: model.layers.15.mlp.down_proj
  Processing layer 113/197: model.layers.16.self_attn.q_proj
  Processing layer 114/197: model.layers.16.self_attn.k_proj
  Processing layer 115/197: model.layers.16.self_attn.v_proj
  Processing layer 116/197: model.layers.16.self_attn.o_proj
  Processing layer 117/197: model.layers.16.mlp.gate_proj
  Processing layer 118/197: model.layers.16.mlp.up_proj
  Processing layer 119/197: model.layers.16.mlp.down_proj
  Processing layer 120/197: model.layers.17.self_attn.q_proj
  Processing layer 121/197: model.layers.17.self_attn.k_proj
  Processing layer 122/197: model.layers.17.self_attn.v_proj
  Processing layer 123/197: model.layers.17.self_attn.o_proj
  Processing layer 124/197: model.layers.17.mlp.gate_proj
  Processing layer 125/197: model.layers.17.mlp.up_proj
  Processing layer 126/197: model.layers.17.mlp.down_proj
  Processing layer 127/197: model.layers.18.self_attn.q_proj
  Processing layer 128/197: model.layers.18.self_attn.k_proj
  Processing layer 129/197: model.layers.18.self_attn.v_proj
  Processing layer 130/197: model.layers.18.self_attn.o_proj
  Processing layer 131/197: model.layers.18.mlp.gate_proj
  Processing layer 132/197: model.layers.18.mlp.up_proj
  Processing layer 133/197: model.layers.18.mlp.down_proj
  Processing layer 134/197: model.layers.19.self_attn.q_proj
  Processing layer 135/197: model.layers.19.self_attn.k_proj
  Processing layer 136/197: model.layers.19.self_attn.v_proj
  Processing layer 137/197: model.layers.19.self_attn.o_proj
  Processing layer 138/197: model.layers.19.mlp.gate_proj
  Processing layer 139/197: model.layers.19.mlp.up_proj
  Processing layer 140/197: model.layers.19.mlp.down_proj
  Processing layer 141/197: model.layers.20.self_attn.q_proj
  Processing layer 142/197: model.layers.20.self_attn.k_proj
  Processing layer 143/197: model.layers.20.self_attn.v_proj
  Processing layer 144/197: model.layers.20.self_attn.o_proj
  Processing layer 145/197: model.layers.20.mlp.gate_proj
  Processing layer 146/197: model.layers.20.mlp.up_proj
  Processing layer 147/197: model.layers.20.mlp.down_proj
  Processing layer 148/197: model.layers.21.self_attn.q_proj
  Processing layer 149/197: model.layers.21.self_attn.k_proj
  Processing layer 150/197: model.layers.21.self_attn.v_proj
  Processing layer 151/197: model.layers.21.self_attn.o_proj
  Processing layer 152/197: model.layers.21.mlp.gate_proj
  Processing layer 153/197: model.layers.21.mlp.up_proj
  Processing layer 154/197: model.layers.21.mlp.down_proj
  Processing layer 155/197: model.layers.22.self_attn.q_proj
  Processing layer 156/197: model.layers.22.self_attn.k_proj
  Processing layer 157/197: model.layers.22.self_attn.v_proj
  Processing layer 158/197: model.layers.22.self_attn.o_proj
  Processing layer 159/197: model.layers.22.mlp.gate_proj
  Processing layer 160/197: model.layers.22.mlp.up_proj
  Processing layer 161/197: model.layers.22.mlp.down_proj
  Processing layer 162/197: model.layers.23.self_attn.q_proj
  Processing layer 163/197: model.layers.23.self_attn.k_proj
  Processing layer 164/197: model.layers.23.self_attn.v_proj
  Processing layer 165/197: model.layers.23.self_attn.o_proj
  Processing layer 166/197: model.layers.23.mlp.gate_proj
  Processing layer 167/197: model.layers.23.mlp.up_proj
  Processing layer 168/197: model.layers.23.mlp.down_proj
  Processing layer 169/197: model.layers.24.self_attn.q_proj
  Processing layer 170/197: model.layers.24.self_attn.k_proj
  Processing layer 171/197: model.layers.24.self_attn.v_proj
  Processing layer 172/197: model.layers.24.self_attn.o_proj
  Processing layer 173/197: model.layers.24.mlp.gate_proj
  Processing layer 174/197: model.layers.24.mlp.up_proj
  Processing layer 175/197: model.layers.24.mlp.down_proj
  Processing layer 176/197: model.layers.25.self_attn.q_proj
  Processing layer 177/197: model.layers.25.self_attn.k_proj
  Processing layer 178/197: model.layers.25.self_attn.v_proj
  Processing layer 179/197: model.layers.25.self_attn.o_proj
  Processing layer 180/197: model.layers.25.mlp.gate_proj
  Processing layer 181/197: model.layers.25.mlp.up_proj
  Processing layer 182/197: model.layers.25.mlp.down_proj
  Processing layer 183/197: model.layers.26.self_attn.q_proj
  Processing layer 184/197: model.layers.26.self_attn.k_proj
  Processing layer 185/197: model.layers.26.self_attn.v_proj
  Processing layer 186/197: model.layers.26.self_attn.o_proj
  Processing layer 187/197: model.layers.26.mlp.gate_proj
  Processing layer 188/197: model.layers.26.mlp.up_proj
  Processing layer 189/197: model.layers.26.mlp.down_proj
  Processing layer 190/197: model.layers.27.self_attn.q_proj
  Processing layer 191/197: model.layers.27.self_attn.k_proj
  Processing layer 192/197: model.layers.27.self_attn.v_proj
  Processing layer 193/197: model.layers.27.self_attn.o_proj
  Processing layer 194/197: model.layers.27.mlp.gate_proj
  Processing layer 195/197: model.layers.27.mlp.up_proj
  Processing layer 196/197: model.layers.27.mlp.down_proj
  Processing layer 197/197: lm_head
  Total parameters: 1,803,288,576
  Ortho parameters: 75,635,900
  Ortho sparsity: 95.81%

[Step 5] Testing canary extraction rates...

  Testing with alpha=1.0...
    Extraction rate: 0.00%

  Testing with alpha=0.5...
    Extraction rate: 0.00%

  Testing with alpha=0.0...
    Extraction rate: 0.00%

============================================================
Results:
============================================================
Extraction Rate (alpha=1.0): 0.00%
Extraction Rate (alpha=0.0): 0.00%
Privacy Ratio: 0.00x
Ortho Sparsity: 95.81%

============================================================
All experiments completed!
Results saved to: experiments/results
============================================================
