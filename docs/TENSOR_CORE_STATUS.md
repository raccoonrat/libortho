# Tensor Core å®ç°çŠ¶æ€

## å½“å‰å®ç°

### âœ… å·²å®Œæˆ

1. **Tensor Core æ¡†æ¶** (`src/dual_gemm_tensor_core.cu`)
   - å®Œæ•´çš„ WMMA API ä½¿ç”¨
   - INT4 -> INT8 è§£åŒ…
   - FP32 -> INT8 é‡åŒ–
   - 16x16 tile å¤„ç†
   - ç´¯åŠ å™¨ç®¡ç†

2. **GPU èƒ½åŠ›æ£€æµ‹** (`check_tensor_core_support()`)
   - è‡ªåŠ¨æ£€æµ‹ compute capability >= 7.0
   - è¿è¡Œæ—¶é€‰æ‹© Tensor Core æˆ–æ ‡å‡† kernel

3. **æ„å»ºç³»ç»Ÿé›†æˆ** (`setup.py`)
   - è‡ªåŠ¨åŒ…å« Tensor Core æºæ–‡ä»¶
   - æ”¯æŒå¤šæ¶æ„ç¼–è¯‘ (sm_75, sm_80, sm_86, sm_89)

### âš ï¸ æ³¨æ„äº‹é¡¹

Tensor Core å®ç°éœ€è¦æ»¡è¶³ä¸¥æ ¼çš„æ•°æ®å¸ƒå±€è¦æ±‚ï¼š

1. **WMMA æ•°æ®å¸ƒå±€**ï¼š
   - `matrix_a` (input): å¿…é¡»æ˜¯ row-major
   - `matrix_b` (weights): å¿…é¡»æ˜¯ col-major
   - `accumulator`: row-major å­˜å‚¨

2. **å†…å­˜å¯¹é½**ï¼š
   - æ‰€æœ‰æ•°æ®å¿…é¡» 128-byte å¯¹é½ï¼ˆå·²å®ç°ï¼‰
   - Shared memory å¸ƒå±€å¿…é¡»åŒ¹é… WMMA è¦æ±‚

3. **é‡åŒ–ç­–ç•¥**ï¼š
   - å½“å‰ä½¿ç”¨ç®€åŒ–çš„æ¯ tile é‡åŒ–
   - ç”Ÿäº§ç¯å¢ƒåº”ä½¿ç”¨æ ¡å‡†çš„é‡åŒ–å°ºåº¦

### ğŸ”„ å¾…ä¼˜åŒ–

1. **è¾“å…¥é‡åŒ–**ï¼š
   - å½“å‰ï¼šç®€åŒ–çš„æ¯ tile é‡åŒ–
   - ä¼˜åŒ–ï¼šä½¿ç”¨æ ¡å‡†çš„é‡åŒ–å°ºåº¦ï¼ˆç±»ä¼¼ GPTQï¼‰

2. **Ortho èåˆ**ï¼š
   - å½“å‰ï¼šBase å’Œ Ortho åˆ†ç¦»è®¡ç®—
   - ä¼˜åŒ–ï¼šå®Œå…¨èåˆçš„åŒæµ Tensor Core kernel

3. **æ‰¹å¤„ç†ä¼˜åŒ–**ï¼š
   - å½“å‰ï¼šæ¯ä¸ª batch å•ç‹¬å¤„ç†
   - ä¼˜åŒ–ï¼šæ‰¹å¤„ç† tile ç®¡ç†

## ä½¿ç”¨æ–¹å¼

### è‡ªåŠ¨é€‰æ‹©ï¼ˆæ¨èï¼‰

```cpp
// orth_layer_forward_cuda() ä¼šè‡ªåŠ¨é€‰æ‹©æœ€ä½³å®ç°
// å¦‚æœ Tensor Core å¯ç”¨ï¼Œä¼˜å…ˆä½¿ç”¨
int result = orth_layer_forward_cuda(&layer, input, output, batch_size);
```

### æ‰‹åŠ¨é€‰æ‹©

```cpp
if (check_tensor_core_support()) {
    orth_layer_forward_tensor_core(&layer, input, output, batch_size);
} else {
    orth_layer_forward_cuda(&layer, input, output, batch_size);
}
```

## æ€§èƒ½é¢„æœŸ

- **æ ‡å‡† CUDA Kernel**: ~100-500 GFLOPS
- **Tensor Core Kernel**: ~1000-5000 GFLOPS (10-50x æå‡)

## æµ‹è¯•å»ºè®®

1. **åŠŸèƒ½æµ‹è¯•**ï¼šéªŒè¯ Tensor Core è¾“å‡ºä¸æ ‡å‡† kernel ä¸€è‡´
2. **æ€§èƒ½æµ‹è¯•**ï¼šå¯¹æ¯” Tensor Core vs æ ‡å‡† kernel çš„æ€§èƒ½
3. **è¾¹ç•Œæµ‹è¯•**ï¼šæµ‹è¯•ä¸åŒçŸ©é˜µå°ºå¯¸ï¼ˆå¿…é¡»æ˜¯ 16 çš„å€æ•°ï¼‰

## å‚è€ƒèµ„æº

- [NVIDIA WMMA API æ–‡æ¡£](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#wmma)
- [CUTLASS åº“](https://github.com/NVIDIA/cutlass) - é«˜çº§ Tensor Core æŠ½è±¡
- [cuBLASLt](https://docs.nvidia.com/cuda/cublas/index.html#cublasltApi) - ä¼˜åŒ–çš„ GEMM åº“

## å½“å‰çŠ¶æ€

âœ… **æ¡†æ¶å®Œæ•´** - å¯ä»¥ç¼–è¯‘å’Œè¿è¡Œ
âš ï¸ **éœ€è¦æµ‹è¯•** - éœ€è¦åœ¨å®é™… GPU ä¸ŠéªŒè¯
ğŸ”„ **å¯ä¼˜åŒ–** - è¾“å…¥é‡åŒ–å’Œèåˆå¯ä»¥è¿›ä¸€æ­¥ä¼˜åŒ–

